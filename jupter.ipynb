{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6857a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml #pip install pandas pyyaml\n",
    "import pandas as pd\n",
    "import mysql.connector #pip install mysql-connector-python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e763df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path                       \n",
    "folder_path = r\"D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\"\n",
    "\n",
    "# Month folders\n",
    "month_name = [\n",
    "    \"2023-10\",\"2023-11\",\"2023-12\",\"2024-01\",\"2024-02\",\"2024-03\",\n",
    "    \"2024-04\",\"2024-05\",\"2024-06\",\"2024-07\",\"2024-08\",\"2024-09\",\"2024-10\",\"2024-11\"\n",
    "]\n",
    "\n",
    "# List to store all YAML data\n",
    "records = []\n",
    "\n",
    "# Loop through all month subfolders\n",
    "for month in month_name:\n",
    "    folder = os.path.join(folder_path, month)\n",
    "    yaml_files = glob.glob(os.path.join(folder, \"*.yaml\"))\n",
    "\n",
    "    for file_path in yaml_files:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = yaml.safe_load(file)\n",
    "            if data:\n",
    "                # Append depending on type\n",
    "                if isinstance(data, dict):\n",
    "                    records.append(data)\n",
    "                elif isinstance(data, list):\n",
    "                    records.extend(data)\n",
    "        print(f\"Loaded {os.path.basename(file_path)} from {month}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138839a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all to one DataFrame\n",
    "df1= pd.DataFrame(records)\n",
    "\n",
    "print(f\"\\nTotal records loaded: {len(df1)}\")\n",
    "print(df1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a4f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"0007\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d36346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection\n",
    "conn = get_connection()\n",
    "\n",
    "# Create a cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create database\n",
    "cursor.execute(\"CREATE DATABASE DATA\")\n",
    "print(\"Database 'DATA' created successfully!\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c712e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MySQL\n",
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"USE DATA\")\n",
    "\n",
    "# Create table\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS MARKET (\n",
    "        Ticker VARCHAR(50),\n",
    "        close DECIMAL(10,2),\n",
    "        date DATETIME,\n",
    "        high DECIMAL(10,2),\n",
    "        low DECIMAL(10,2),\n",
    "        month VARCHAR(10),\n",
    "        open DECIMAL(10,2),\n",
    "        volume INT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Table 'MARKET' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"USE DATA\")\n",
    "# Loop through DataFrame rows\n",
    "for _, row in df1.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO MARKET (Ticker, close, date, high, low, month,open,volume)\n",
    "        VALUES (%s, %s, %s, %s, %s,%s, %s,%s)\n",
    "    \"\"\", (\n",
    "        row.get(\"Ticker\"),\n",
    "        row.get(\"close\"),\n",
    "        row.get(\"date\"),\n",
    "        row.get(\"high\"),\n",
    "        row.get(\"low\"),\n",
    "        row.get(\"month\"),\n",
    "        row.get(\"open\"),\n",
    "        row.get(\"volume\")\n",
    "    ))\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted successfully into 'MARKET'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51a8d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers found: ['SBIN', 'BAJFINANCE', 'TITAN', 'ITC', 'TCS', 'LT', 'TATACONSUM', 'RELIANCE', 'HCLTECH', 'JSWSTEEL', 'ULTRACEMCO', 'POWERGRID', 'INFY', 'TRENT', 'BHARTIARTL', 'TATAMOTORS', 'WIPRO', 'TECHM', 'NTPC', 'HINDUNILVR', 'APOLLOHOSP', 'M&M', 'GRASIM', 'ICICIBANK', 'ADANIENT', 'ADANIPORTS', 'BEL', 'BAJAJFINSV', 'EICHERMOT', 'COALINDIA', 'MARUTI', 'INDUSINDBK', 'ASIANPAINT', 'TATASTEEL', 'HDFCLIFE', 'DRREDDY', 'SUNPHARMA', 'KOTAKBANK', 'SHRIRAMFIN', 'NESTLEIND', 'ONGC', 'CIPLA', 'BPCL', 'BRITANNIA', 'SBILIFE', 'HINDALCO', 'HEROMOTOCO', 'AXISBANK', 'HDFCBANK', 'BAJAJ-AUTO']\n",
      "Processing SBIN...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\SBIN.csv\n",
      "Processing BAJFINANCE...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\BAJFINANCE.csv\n",
      "Processing TITAN...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\TITAN.csv\n",
      "Processing ITC...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\ITC.csv\n",
      "Processing TCS...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\TCS.csv\n",
      "Processing LT...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\LT.csv\n",
      "Processing TATACONSUM...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\TATACONSUM.csv\n",
      "Processing RELIANCE...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\RELIANCE.csv\n",
      "Processing HCLTECH...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\HCLTECH.csv\n",
      "Processing JSWSTEEL...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\JSWSTEEL.csv\n",
      "Processing ULTRACEMCO...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\ULTRACEMCO.csv\n",
      "Processing POWERGRID...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\POWERGRID.csv\n",
      "Processing INFY...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\INFY.csv\n",
      "Processing TRENT...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\TRENT.csv\n",
      "Processing BHARTIARTL...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\BHARTIARTL.csv\n",
      "Processing TATAMOTORS...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\TATAMOTORS.csv\n",
      "Processing WIPRO...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\WIPRO.csv\n",
      "Processing TECHM...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\TECHM.csv\n",
      "Processing NTPC...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\NTPC.csv\n",
      "Processing HINDUNILVR...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\HINDUNILVR.csv\n",
      "Processing APOLLOHOSP...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\APOLLOHOSP.csv\n",
      "Processing M&M...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\M&M.csv\n",
      "Processing GRASIM...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\GRASIM.csv\n",
      "Processing ICICIBANK...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\ICICIBANK.csv\n",
      "Processing ADANIENT...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\ADANIENT.csv\n",
      "Processing ADANIPORTS...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\ADANIPORTS.csv\n",
      "Processing BEL...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\BEL.csv\n",
      "Processing BAJAJFINSV...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\BAJAJFINSV.csv\n",
      "Processing EICHERMOT...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\EICHERMOT.csv\n",
      "Processing COALINDIA...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\COALINDIA.csv\n",
      "Processing MARUTI...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\MARUTI.csv\n",
      "Processing INDUSINDBK...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\INDUSINDBK.csv\n",
      "Processing ASIANPAINT...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\ASIANPAINT.csv\n",
      "Processing TATASTEEL...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\TATASTEEL.csv\n",
      "Processing HDFCLIFE...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\HDFCLIFE.csv\n",
      "Processing DRREDDY...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\DRREDDY.csv\n",
      "Processing SUNPHARMA...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\SUNPHARMA.csv\n",
      "Processing KOTAKBANK...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\KOTAKBANK.csv\n",
      "Processing SHRIRAMFIN...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\SHRIRAMFIN.csv\n",
      "Processing NESTLEIND...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\NESTLEIND.csv\n",
      "Processing ONGC...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\ONGC.csv\n",
      "Processing CIPLA...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\CIPLA.csv\n",
      "Processing BPCL...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\BPCL.csv\n",
      "Processing BRITANNIA...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\BRITANNIA.csv\n",
      "Processing SBILIFE...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\SBILIFE.csv\n",
      "Processing HINDALCO...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\HINDALCO.csv\n",
      "Processing HEROMOTOCO...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\HEROMOTOCO.csv\n",
      "Processing AXISBANK...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\AXISBANK.csv\n",
      "Processing HDFCBANK...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\HDFCBANK.csv\n",
      "Processing BAJAJ-AUTO...\n",
      "Saved: D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\\output_csv\\BAJAJ-AUTO.csv\n",
      "✅ All ticker data exported to CSV successfully!\n"
     ]
    }
   ],
   "source": [
    "# Folder to save CSV files\n",
    "output_folder =os.path.join(folder_path,\"output_csv\") #r\"D:\\data_driven\\output_csv\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"USE DATA\")\n",
    "\n",
    "# Step 1: Get distinct tickers\n",
    "cursor.execute(\"SELECT DISTINCT Ticker FROM MARKET\")\n",
    "companies = [row[0] for row in cursor.fetchall()]  # flatten to list\n",
    "print(\"Tickers found:\", companies)\n",
    "\n",
    "# Step 2: Loop through each ticker, fetch data, and save as CSV\n",
    "for ticker in companies:\n",
    "    print(f\"Processing {ticker}...\")\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT Ticker, close, date, high, low, month, open,volume\n",
    "        FROM MARKET\n",
    "        WHERE Ticker = %s\n",
    "    \"\"\", (ticker,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows, columns=[\"Ticker\", \"close\", \"date\", \"high\", \"low\", \"month\", \"open\",\"volume\"])\n",
    "\n",
    "    # Step 3: Save to CSV\n",
    "    csv_path = os.path.join(output_folder, f\"{ticker}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Saved: {csv_path}\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ All ticker data exported to CSV successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
