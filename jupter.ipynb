{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6857a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml #pip install pandas pyyaml\n",
    "import pandas as pd\n",
    "import mysql.connector #pip install mysql-connector-python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e763df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path                       \n",
    "folder_path = r\"D:\\PROJECT_2\\Data-Driven-Stock-Analysis\\data\"\n",
    "\n",
    "# Month folders\n",
    "month_name = [\n",
    "    \"2023-10\",\"2023-11\",\"2023-12\",\"2024-01\",\"2024-02\",\"2024-03\",\n",
    "    \"2024-04\",\"2024-05\",\"2024-06\",\"2024-07\",\"2024-08\",\"2024-09\",\"2024-10\",\"2024-11\"\n",
    "]\n",
    "\n",
    "# List to store all YAML data\n",
    "records = []\n",
    "\n",
    "# Loop through all month subfolders\n",
    "for month in month_name:\n",
    "    folder = os.path.join(folder_path, month)\n",
    "    yaml_files = glob.glob(os.path.join(folder, \"*.yaml\"))\n",
    "\n",
    "    for file_path in yaml_files:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = yaml.safe_load(file)\n",
    "            if data:\n",
    "                # Append depending on type\n",
    "                if isinstance(data, dict):\n",
    "                    records.append(data)\n",
    "                elif isinstance(data, list):\n",
    "                    records.extend(data)\n",
    "        print(f\"Loaded {os.path.basename(file_path)} from {month}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138839a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all to one DataFrame\n",
    "df1= pd.DataFrame(records)\n",
    "\n",
    "print(f\"\\nTotal records loaded: {len(df1)}\")\n",
    "print(df1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a4f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"0007\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d36346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection\n",
    "conn = get_connection()\n",
    "\n",
    "# Create a cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create database\n",
    "cursor.execute(\"CREATE DATABASE DATA\")\n",
    "print(\"Database 'DATA' created successfully!\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c712e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MySQL\n",
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"USE DATA\")\n",
    "\n",
    "# Create table\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS MARKET (\n",
    "        Ticker VARCHAR(50),\n",
    "        close DECIMAL(10,2),\n",
    "        date DATETIME,\n",
    "        high DECIMAL(10,2),\n",
    "        low DECIMAL(10,2),\n",
    "        month VARCHAR(10),\n",
    "        open DECIMAL(10,2),\n",
    "        volume INT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Table 'MARKET' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"USE DATA\")\n",
    "# Loop through DataFrame rows\n",
    "for _, row in df1.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO MARKET (Ticker, close, date, high, low, month,open,volume)\n",
    "        VALUES (%s, %s, %s, %s, %s,%s, %s,%s)\n",
    "    \"\"\", (\n",
    "        row.get(\"Ticker\"),\n",
    "        row.get(\"close\"),\n",
    "        row.get(\"date\"),\n",
    "        row.get(\"high\"),\n",
    "        row.get(\"low\"),\n",
    "        row.get(\"month\"),\n",
    "        row.get(\"open\"),\n",
    "        row.get(\"volume\")\n",
    "    ))\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted successfully into 'MARKET'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to save CSV files\n",
    "output_folder =os.path.join(folder_path,\"output_csv\") #r\"D:\\data_driven\\output_csv\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "conn = get_connection()\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"USE DATA\")\n",
    "\n",
    "# Step 1: Get distinct tickers\n",
    "cursor.execute(\"SELECT DISTINCT Ticker FROM MARKET\")\n",
    "companies = [row[0] for row in cursor.fetchall()]  # flatten to list\n",
    "print(\"Tickers found:\", companies)\n",
    "\n",
    "# Step 2: Loop through each ticker, fetch data, and save as CSV\n",
    "for ticker in companies:\n",
    "    print(f\"Processing {ticker}...\")\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT Ticker, close, date, high, low, month, open,volume\n",
    "        FROM MARKET\n",
    "        WHERE Ticker = %s\n",
    "    \"\"\", (ticker,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows, columns=[\"Ticker\", \"close\", \"date\", \"high\", \"low\", \"month\", \"open\",\"volume\"])\n",
    "\n",
    "    # Step 3: Save to CSV\n",
    "    csv_path = os.path.join(output_folder, f\"{ticker}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Saved: {csv_path}\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"‚úÖ All ticker data exported to CSV successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eec7b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0c089ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join(folder_path, \"output_csv\")\n",
    "all_files = glob.glob(os.path.join(output_folder, \"*.csv\"))\n",
    "\n",
    "list_val=[]\n",
    "DATE_COL = 'date'\n",
    "CLOSE_COL = 'close'\n",
    "\n",
    "for filename in all_files:\n",
    "    df2 = pd.read_csv(filename)\n",
    "    ticker = os.path.splitext(os.path.basename(filename))[0].upper()\n",
    "    df_cleaned = df2[[DATE_COL, CLOSE_COL]].copy()\n",
    "    df_cleaned.rename(columns={DATE_COL: 'Date', CLOSE_COL: 'Close'}, inplace=True)\n",
    "    df_cleaned['Ticker'] = ticker\n",
    "    list_val.append(df_cleaned)\n",
    "\n",
    "combined_df = pd.concat(list_val, axis=0, ignore_index=True)\n",
    "combined_df.to_csv(\"combined_stock_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b545ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ca835e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=combined_df['Ticker'].unique()\n",
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e896f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "combined_df['Close'] = pd.to_numeric(combined_df['Close'], errors='coerce')\n",
    "combined_df = combined_df.dropna(subset=['Close'])\n",
    "combined_df = combined_df.sort_values(by=['Ticker', 'Date'])\n",
    "\n",
    "combined_df['Daily_Return'] = combined_df.groupby('Ticker')['Close'].pct_change()\n",
    "returns_df = combined_df.dropna(subset=['Daily_Return'])\n",
    "volatility = returns_df.groupby('Ticker')['Daily_Return'].std().reset_index()\n",
    "volatility.columns = ['Ticker', 'Volatility']\n",
    "top_10_volatility = volatility.sort_values(by='Volatility', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_10_volatility['Ticker'], top_10_volatility['Volatility'], color='teal')\n",
    "plt.xlabel('Stock Ticker')\n",
    "plt.ylabel('Volatility (Standard Deviation of Daily Returns)')\n",
    "plt.title('Top 10 Most Volatile Stocks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_10_volatility_bar_chart.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- READ COMBINED CSV FILES ---\n",
    "output_folder = os.path.join(folder_path, \"output_csv\")\n",
    "all_files = glob.glob(os.path.join(output_folder, \"*.csv\"))\n",
    "\n",
    "list_val = []\n",
    "DATE_COL = 'date'\n",
    "CLOSE_COL = 'close'\n",
    "\n",
    "for filename in all_files:\n",
    "    df2 = pd.read_csv(filename)\n",
    "    ticker = os.path.splitext(os.path.basename(filename))[0].upper()\n",
    "\n",
    "    df_cum = df2[[DATE_COL, CLOSE_COL]].copy()\n",
    "    df_cum.rename(columns={DATE_COL: 'Date', CLOSE_COL: 'Close'}, inplace=True)\n",
    "    df_cum['Ticker'] = ticker\n",
    "\n",
    "    list_val.append(df_cum)\n",
    "\n",
    "cum_df = pd.concat(list_val, axis=0, ignore_index=True)\n",
    "\n",
    "# Sort by date (important!)\n",
    "cum_df['Date'] = pd.to_datetime(cum_df['Date'])\n",
    "cum_df.sort_values(by=['Ticker', 'Date'], inplace=True)\n",
    "\n",
    "# Calculate cumulative return\n",
    "cum_df['Start_Close'] = cum_df.groupby(\"Ticker\")['Close'].transform('first')\n",
    "cum_df['Cumulative_Return'] = (cum_df['Close'] / cum_df['Start_Close']) - 1\n",
    "cum_df['Cumulative_Return_Percent'] = cum_df['Cumulative_Return'] * 100\n",
    "\n",
    "# ------------- SELECT TOP 5 STOCKS -----------------\n",
    "\n",
    "# Get last cumulative return value per stock\n",
    "final_cum = cum_df.groupby(\"Ticker\")['Cumulative_Return'].last().reset_index()\n",
    "\n",
    "# Pick top 5 performing stocks\n",
    "top5_tickers = final_cum.sort_values(by='Cumulative_Return', ascending=False).head(5)['Ticker']\n",
    "print(\"Top 5 Stocks Based on Cumulative Return:\")\n",
    "print(top5_tickers)\n",
    "\n",
    "# Filter data for only these 5 stocks\n",
    "top5_df = cum_df[cum_df['Ticker'].isin(top5_tickers)]\n",
    "\n",
    "# ------------- PLOT CUMULATIVE RETURNS --------------\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for ticker in top5_tickers:\n",
    "    df_plot = top5_df[top5_df['Ticker'] == ticker]\n",
    "    plt.plot(df_plot['Date'], df_plot['Cumulative_Return'], label=ticker)\n",
    "\n",
    "plt.title(\"Cumulative Return Over Time - Top 5 Performing Stocks\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 1. Load sector mapping\n",
    "# ----------------------------\n",
    "sector_map = pd.read_csv(r\"D:\\data_driven\\.dds\\Sector_data - Sheet1.csv\")  # stock, sector\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Load combined stock price dataset\n",
    "# ----------------------------\n",
    "output_folder = os.path.join(folder_path, \"output_csv\")\n",
    "all_files = glob.glob(os.path.join(output_folder, \"*.csv\"))\n",
    "\n",
    "sect_tick=[]\n",
    "all_daa=[]\n",
    "for filename in all_files:\n",
    "    df2 = pd.read_csv(filename)\n",
    "    ticker = os.path.splitext(os.path.basename(filename))[0].upper()\n",
    "    df_cleaned = df2.copy()\n",
    "    all_daa.append(df_cleaned)\n",
    "    sect_tick.append(ticker)\n",
    "\n",
    "combined_df = pd.concat(all_daa, axis=0, ignore_index=True)\n",
    "combined_df.to_csv(\"sector_ticker.csv\", index=False)  # date, stock, close\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "\n",
    "n=pd.DataFrame(sect_tick,columns=[\"Ticker\"])\n",
    "sector_map[\"COMPANY\"]=n[\"Ticker\"]\n",
    "sector_map.rename(columns={\"COMPANY\":\"Ticker\"},inplace=True)\n",
    "# ----------------------------\n",
    "# 3. Calculate yearly return for each stock\n",
    "# ----------------------------\n",
    "# Get first and last price for each stock\n",
    "first_last = combined_df.sort_values('date').groupby('Ticker').agg(\n",
    "    first_price=('close', 'first'),\n",
    "    last_price=('close', 'last')\n",
    ")\n",
    "\n",
    "first_last['yearly_return'] = (first_last['last_price'] - first_last['first_price']) / first_last['first_price'] * 100\n",
    "first_last.reset_index(inplace=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Merge sector data\n",
    "# ----------------------------\n",
    "merged = pd.merge(first_last, sector_map, on='Ticker', how='left')\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Calculate average yearly return by sector\n",
    "# ----------------------------\n",
    "sector_perf = merged.groupby('sector')['yearly_return'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nAverage Sector-wise Returns:\")\n",
    "print(sector_perf)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Plot bar chart\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(12,6))\n",
    "sector_perf.plot(kind='bar')\n",
    "\n",
    "plt.title(\"Average Yearly Return by Sector\")\n",
    "plt.xlabel(\"Sector\")\n",
    "plt.ylabel(\"Average Yearly Return (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1fb8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_1=r\"D:\\data_driven\\data\\Sector_data - Sheet1.csv\"\n",
    "def avg_year_returns(folder_path,folder_path_1):\n",
    "    sector_map = pd.read_csv(folder_path_1)  # stock, sector\n",
    "    output_folder = os.path.join(folder_path, \"output_csv\")\n",
    "    all_files = glob.glob(os.path.join(output_folder, \"*.csv\"))\n",
    "    sect_tick=[]\n",
    "    all_daa=[]\n",
    "    for filename in all_files:\n",
    "        df2 = pd.read_csv(filename)\n",
    "        ticker = os.path.splitext(os.path.basename(filename))[0].upper()\n",
    "        df_cleaned = df2.copy()\n",
    "        all_daa.append(df_cleaned)\n",
    "        sect_tick.append(ticker)\n",
    "    combined_df = pd.concat(all_daa, axis=0, ignore_index=True)\n",
    "    combined_df.to_csv(\"sector_ticker.csv\", index=False)  # date, stock, clos\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "    n=pd.DataFrame(sect_tick,columns=[\"Ticker\"])\n",
    "    sector_map[\"COMPANY\"]=n[\"Ticker\"]\n",
    "    sector_map.rename(columns={\"COMPANY\":\"Ticker\"},inplace=True)\n",
    "\n",
    "    first_last = combined_df.sort_values('date').groupby('Ticker').agg(\n",
    "        first_price=('close', 'first'),\n",
    "        last_price=('close', 'last'))\n",
    "    first_last['yearly_return'] = (first_last['last_price'] - first_last['first_price']) / first_last['first_price'] * 100\n",
    "    first_last.reset_index(inplace=True)\n",
    "    merged = pd.merge(first_last, sector_map, on='Ticker', how='left')\n",
    "    sector_perf = merged.groupby('sector')['yearly_return'].mean().sort_values(ascending=False)\n",
    "    print(\"\\nAverage Sector-wise Returns:\")\n",
    "    print(sector_perf)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sector_perf.plot(kind='bar')\n",
    "    plt.title(\"Average Yearly Return by Sector\")\n",
    "    plt.xlabel(\"Sector\")\n",
    "    plt.ylabel(\"Average Yearly Return (%)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b968cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- READ ALL STOCK CSV FILES ---\n",
    "def stock_correlation(folder_path):\n",
    "    output_folder = os.path.join(folder_path, \"output_csv\")\n",
    "    all_files = glob.glob(os.path.join(output_folder, \"*.csv\"))\n",
    "\n",
    "    stock_dict = {}   # Ticker ‚Üí its closing prices\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        # Extract ticker name from filename\n",
    "        ticker = os.path.splitext(os.path.basename(filename))[0].upper()\n",
    "\n",
    "        # Clean dataframe: convert date & sort\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date')\n",
    "\n",
    "        # Set date as index\n",
    "        df = df.set_index('date')\n",
    "\n",
    "        # Keep only the Close column\n",
    "        stock_dict[ticker] = df['close']\n",
    "\n",
    "    # Combine all stocks into a single DataFrame by date\n",
    "    combined_df = pd.DataFrame(stock_dict)\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = combined_df.corr()\n",
    "\n",
    "    print(\"\\nüîç STOCK PRICE CORRELATION MATRIX:\")\n",
    "    print(corr_matrix)\n",
    "\n",
    "    # ---------------- PLOT HEATMAP -------------------\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(corr_matrix, cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "    plt.colorbar(label=\"Correlation Coefficient\")\n",
    "\n",
    "    # Add ticks and labels\n",
    "    plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr_matrix.index)), corr_matrix.index)\n",
    "\n",
    "    plt.title(\"Stock Price Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d40de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join(folder_path, \"output_csv\")\n",
    "all_files = glob.glob(os.path.join(output_folder, \"*.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0804660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_daa=[]\n",
    "for filename in all_files:\n",
    "    df2 = pd.read_csv(filename)\n",
    "    df_cleaned = df2.copy()\n",
    "    all_daa.append(df_cleaned)\n",
    "combined_df = pd.concat(all_daa, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080617cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.groupby([\"Ticker\",\"month\"])[\"close\"].agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53e4b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "    # Read all CSV files and combine\n",
    "for file in all_files:\n",
    "    ticker = os.path.splitext(os.path.basename(file))[0].upper()\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['Ticker'] = ticker\n",
    "    all_data.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = combined_df.sort_values('date').groupby(['Ticker', 'Month'])['close'].agg(['first', 'last'])\n",
    "monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c32a7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # ---- Extract month in YYYY-MM format ----\n",
    "combined_df['Month'] = combined_df['date'].dt.to_period('M').astype(str)\n",
    "\n",
    "    # ---- Calculate Monthly Returns ----\n",
    "monthly = combined_df.sort_values('date').groupby(['Ticker', 'Month'])['close'].agg(['first', 'last'])\n",
    "\n",
    "monthly['Monthly_Return'] = ((monthly['last'] - monthly['first']) / monthly['first']) * 100\n",
    "monthly.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_months = monthly['Month'].unique()\n",
    "\n",
    "    # Create 12 charts (one per month)\n",
    "for month in unique_months:\n",
    "        df_month = monthly[monthly['Month'] == month]\n",
    "\n",
    "        top5_gainers = df_month.nlargest(5, 'Monthly_Return')\n",
    "        top5_losers = df_month.nsmallest(5, 'Monthly_Return')\n",
    "\n",
    "        # ---- Plot ----\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "        # Gainers\n",
    "        axes[0].barh(top5_gainers['Ticker'], top5_gainers['Monthly_Return'])\n",
    "        axes[0].set_title(f\"Top 5 Gainers - {month}\")\n",
    "        axes[0].set_xlabel(\"Monthly Return (%)\")\n",
    "\n",
    "        # Losers\n",
    "        axes[1].barh(top5_losers['Ticker'], top5_losers['Monthly_Return'], color='red')\n",
    "        axes[1].set_title(f\"Top 5 Losers - {month}\")\n",
    "        axes[1].set_xlabel(\"Monthly Return (%)\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
